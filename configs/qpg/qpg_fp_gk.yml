
type:                             QRL                   # choose a type: RL, GA, Hypernetwork (DEPRECATED)
alg:                              QPG                   # name of the algorithm
seed:                             42                    # seed for ray alogorithms/tensorflow/pytorch for reproduceabel results
constant_seed:                    False                 # setting the same seed accross all runs
checkpoint_at_end:                True                  # create checkpoint at the end of training
checkpoint_freq:                  1000                  # set checkpoint frequency, depends on training iterations
ray_local_mode:                   False                  # set local_mode of ray to True for debugging
ray_logging_path:                 logs/qpg/fp/02_28     # logging directory
total_num_cpus:                   24                    # total number of cpus
total_num_gpus:                   0                     # total number of gpus
ray_num_trial_samples:            3                     # number of hyperparameter combinations (trials) to run (works differently for grid_search)
training_iterations:              500                   # number of training iterations
run_sections:                                           # specifiy the code you want to run
                                # - qrl_training
                                - plotting
                                # - landscape_plotting
                                # - algorithm_training
                                # - variance_calculation
                                    
###########################################################################
env:                              FP
env_config:
  units:                          3
  mode:                           dynamic_9 
  lambda:                         1.0
  power_scaling:                  1.0
  episode_length:                 10
  reward_mode:                    optimal_spike
  action_space_type:              multi_discrete
  path:                           /home/users/kruse/quantum-computing/QRL/games/fp/tai60a.dat

###########################################################################
algorithm_config:                                       # config for QRL training
  reuse_actors:                   True
  num_gpus:                       0                     # number of gpus for each trial
  num_rollout_workers:            1                     # number of worker for each trial. By ray default, every worker needs one cpu
  num_envs_per_worker:            1                     # number of game enviroments for each worker
  num_gpus_per_worker:            0                     # number of gpus for each worker
  num_cpus_per_worker:            2                     # number of cpus for each worker
  framework:                      torch                 # ray framework [torch, tensorflow]
  ###########################################################################
  lr:                             #0.025                # select lr for nn, variational params and input scaling params
    - grid_search
    - float
    - [0.025, 0.01, 0.005]
  lr_output_scaling:              #0.1                  # select lr for output scaling params
    - grid_search
    - float
    - [0.05, 0.01]
  num_layers:                     1                     # select number of layers of vqc (layer nn defined below)
  ###########################################################################
  mode:                           quantum               # select mode [classical, quantum, hybrid]
  interface:                      torch                 # select pennylane interface, default: torch
  diff_method:                    adjoint               # select pennylane diff_method [adjoing, backprop, ...] 
  backend_name:                   lightning.qubit       # select pennylane backend [lightning.qubit, default.qubit, ...]
  custom_optimizer:               Adam                  # select the classical optimizer [Adam, RMSprop, LBFGS, ...] 
  ###########################################################################
  vqc_type:                       [vqc_generator, 9]    # select vqc_generator or other circuit generator function + number of qubits
  use_hadamard:                   True                  # Create equal superposition in the beginning
  block_sequence:                 enc                   # select the block sequence, enc_var_ent == classical hwe ansatz, graph_encoding only needs enc
  encoding_type:                  graph_encoding        # data encoding type [angular_classical (RY_RZ), layerwise_arctan_sigmoid, graph_encoding ... ]
  graph_encoding_type:            #angular-hwe           # if encoding_type=graph_encoding, than select [s-ppgl, m-ppgl, h-ppgl, hamiltonian-hwe, angular-hwe, angular, ...]
    - grid_search
    - string
    - [s-ppgl, m-ppgl, h-ppgl, s-ppgl-linear, m-ppgl-linear, angular-hwe] 
  use_input_scaling:              True                  # use input scaling [True, False] -> main parameters for graph encoding of eqc/neqc 
  init_input_scaling_actor:       [1.]                  # if list, then each gate gets one params, if single float, all have same param [[1.], 1., ...]
  num_scaling_params:             2                     # select the number of params, so e.g. 2 for angular_classical -> RY_RZ
  variational_type:               RZ_RY                 # select the gate sequence [RZ_RY, RY_RZ]
  num_variational_params:         2                     # select the number of params, so e.g. 2 for RZ_RY
  init_variational_params:        0.1                   # select initialization of the variational parameters
  init_variational_params_mode:   plus-zero-uniform     # plus-zero-uniform, plus-plus-normal, plus-zero-normal
  entangling_type:                chain                 # type of entanglement [chain, full, ...]
  entangling_gate:                CZ                    # type of entanglement gate [CNOT, CZ, CH, ...]
  measurement_type_actor:         exp                   # type of measurement (check the python files for examples) (exp for discrete) exp_@_exp+exp
  use_output_scaling_actor:       True                  # use output scaling [True, False]
  init_output_scaling_actor:      [1.]                  # if list, then each qubit gets one param, if single float, all have same param [[1.], 1., ...]
  postprocessing_actor:           1                     # select postprocessing (check the file postprocessing.py)
  ###########################################################################
  noise:                                                # use noise during training
    coherent:                     [False, 0.]           # bool + float for magnitude of used coherent noise
    depolarizing:                 [False, 0.001]        # bool + float for magnitude of used depolarizing noise
  layerwise_training:             False                 # layerwise training (DEPRECATED)
  gradient_clipping:              False                 # gradient clipping (DEPRECATED)
  use_classical_layer:            False                 # additional postprocessing (DEPRECATED)
  layer_size:                     [64, 64]              # classical NN, max 3 layers with in as number of neurons in the according layer
  activation_function:            relu                  # activation function of classical NN
  weight_logging_interval:        5000                  # weight logging + plotting interval (DEPRECATED)
  weight_plotting:                False                 # weight logging + plotting (DEPRECATED)
  ###########################################################################
  # More ray params
  explore:                        True
    # - grid_search
    # - string
    # - [False, True]
###########################################################################


evaluation:
  set_seed:               True 
  seed:                   694
  ###########################################################################
  plotting:
    mode:                         custom
    path:                         logs/qpg/fp/02_28/2024-03-01--14-40-58_QRL_QPG
  ###########################################################################
  landscape_plotting:
    mode:                 qaoa
    plot_name:            qaoa 4 qubits params=10 layer=5 
    plot_title:           qaoa 4 qubits params=10 layer=5 
    center_params:        trained_model                       # can either be 0, trained_model
    center_params_path:   'logs/comp/static/2024-02-06--13-09-33/params_qaoa_qubits_4_layer_5_timestep_0.csv'
                          # e.g. qrl: 'logs/qpg/uc/01_15/2024-01-17--11-39-09_QRL_QPG/QRL_PG_UC_demo_a552e_00000_0_graph_encoding_type=eqc,num_layers=3_2024-01-17_11-39-09/checkpoint_001000'
                          # e.g. qnn, qaoa, vqe: 'logs/comp/dynamic_5/2024-01-22--12-04-12/params_qnn_qubits_5_layer_5.csv'
    number_dimensions:    10
    evaluation_steps:     10                                  # only required for qnn and qrl 
    vqc_type:             qaoa #               qaoa, vqe, qrl, custom_circuit
    num_layers: 5
    num_params: 2
    num_qubits: 4
    num_div:  50                                            # Number of divisions to search (granularity of the grid / number of data points)
    metric:     accuracy #, reward, loss
    mark_optimal:   [True, 10]
    save_to_json:   False
    scalor_1: 0.1
    scalor_2: 1.0
  ###########################################################################
  algorithm_training:
    alg_to_evaluate:              [qaoa]
    qrl_path:                     'logs/qpg/uc/01_08/2024-01-08--14-06-16_QRL_QPG/QRL_PG_UC_demo_b5340_00002_2_lr=0.0010_2024-01-08_14-06-36/checkpoint_000500'
    optimizer_steps:              100
    num_qubits:                   4
    layer:
      layer_vqe:                  5
      layer_qaoa:                 1
      layer_qnn:                  5
    initialization:
      init_vqe:           0.5
      init_qaoa:          0.1
      init_qnn:           0.1
    lr:
      lr_vqe:             0.1
      lr_qaoa:            0.0001
      lr_qnn:             0.1
    params_vqe:           2
    params_qnn:           10
    plotting:
      plot_vqe_probs:     True
      plot_qaoa_probs:    True
      plot_qnn_probs:     True
    landscape_plotting:   True
###########################################################################
  variance_calculation:   
    qubits:               [4, 6, 8, 10]
    logging_path:         'logs/comp'
    interface:            adjoint                             # torch doesnt work
    calc_vars:            False
    plot_vars:            True
    fig_name:             'variance calculation eqc, neqc, angular 20 layer var_weights_0 + exp'
    paths: ['/home/users/kruse/quantum-computing/QRL/logs/qpg/uc/01_09/2024-02-02--17-09-23_variances']
    plot_keys:
      - var_all_gradients
      - var_expecation
      - var_weights_0
      - var_input_scaling_0
 


  